=== Seq2Seq Chatbot Model Evaluation Results ===

Evaluation Date: 2025-08-02 00:01:10
Device Used: mps
Test set size: 342 samples
Vocabulary size: 5748

Seq2Seq without Attention:
  BLEU Score: 0.1338
  Accuracy: 0.4152
  BERT Precision: 0.9207
  BERT Recall: 0.9171
  BERT F1: 0.9183

Seq2Seq with Luong Attention:
  BLEU Score: 0.1169
  Accuracy: 0.3889
  BERT Precision: 0.9296
  BERT Recall: 0.9194
  BERT F1: 0.9240

Improvements (With Attention - Without Attention):
  BLEU Score: -0.0169
  Accuracy: -0.0263
  BERT Precision: 0.0089
  BERT Recall: 0.0024
  BERT F1: 0.0056
