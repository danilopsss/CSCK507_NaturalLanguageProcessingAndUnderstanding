=== Seq2Seq Chatbot Model Evaluation Results ===

Evaluation Date: 2025-07-31 20:38:19
Device Used: mps
Test set size: 342 samples
Vocabulary size: 5748

Seq2Seq without Attention:
  BLEU Score: 0.1338
  Accuracy: 0.4152

Seq2Seq with Luong Attention:
  BLEU Score: 0.1169
  Accuracy: 0.3889

Improvements (With Attention - Without Attention):
  BLEU Score: -0.0169
  Accuracy: -0.0263
