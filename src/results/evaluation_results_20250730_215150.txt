=== Seq2Seq Chatbot Model Evaluation Results ===

Evaluation Date: 2025-07-30 21:51:50
Device Used: mps
Test set size: 342 samples
Vocabulary size: 5748

Seq2Seq without Attention:
  BLEU Score: 0.0631
  Accuracy: 0.3363

Seq2Seq with Luong Attention:
  BLEU Score: 0.1353
  Accuracy: 0.4181

Improvements (With Attention - Without Attention):
  BLEU Score: 0.0722
  Accuracy: 0.0819
